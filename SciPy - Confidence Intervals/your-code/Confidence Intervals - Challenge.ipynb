{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 1\n",
    "We want to estimate the average size of the men of a country with a confidence level of 80%. Assuming that the standard deviation of the sizes in the population is 4, get the confidence interval with a sample of men selected randomly, whose heights are:\n",
    "\n",
    "````\n",
    "heights = [167, 167, 168, 168, 168, 169, 171, 172, 173, 175, 175, 175, 177, 182, 195]\n",
    "````\n",
    "\n",
    "**Hint**: function `stats.norm.interval` from `scipy` can help you get through this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining 1D np array heights\n",
    "heights = [167, 167, 168, 168, 168, 169, 171, 172, 173, 175, 175, 175, 177, 182, 195]\n",
    "\n",
    "pop_std = 4\n",
    "\n",
    "c_l = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(heights)\n",
    "\n",
    "#calculating std of the sample\n",
    "sample_std = pop_std / np.sqrt(len(heights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[172.14308590115726, 174.79024743217607]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classical Math method\n",
    "#Confidence interval formula = mean +- z value * std/sqr(n)\n",
    "confidence_intervals_math = [mean -  norm.interval(c_l)[1] * sample_std\n",
    "                            ,mean + norm.interval(c_l)[1] * sample_std]\n",
    "\n",
    "confidence_intervals_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172.14308590115726, 174.79024743217607)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SciPy Method - using stats.norm.interval function\n",
    "stats.norm.interval(c_l, loc=np.mean(heights), scale=sample_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 2 \n",
    "In a sample of 105 shops selected randomly from an area, we note that 27 of them have had losses in this month. Get an interval for the proportion of businesses in the area with losses to a confidence level of 80% and a confidence level of 90%.\n",
    "\n",
    "**Hint**: function `stats.norm.interval` from `scipy` can help you get through this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_80 = 0.8\n",
    "\n",
    "cl_90 = 0.9\n",
    "\n",
    "total_shop = 105\n",
    "\n",
    "loss_shop = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2571428571428571"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating p_hat\n",
    "p_hat_shop = loss_shop / total_shop\n",
    "\n",
    "p_hat_shop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042652572988124506"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating standard error\n",
    "\n",
    "# Standard_error formula\n",
    "#np.sqrt((Sample_proportion * (1 - Sample_proportion)) / the_random_sample)\n",
    "shop_s_e = np.sqrt((p_hat_shop*(1-p_hat_shop)/total_shop))\n",
    "\n",
    "shop_s_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval 80%: (0.20248138545542083, 0.3118043288302934)\n"
     ]
    }
   ],
   "source": [
    "#calculating confidence interval for the confidence level of 80%\n",
    "interval_80_proportion = stats.norm.interval(alpha=cl_80, loc=p_hat_shop ,scale=shop_s_e)\n",
    "\n",
    "print(f\"Confidence interval 80%: {interval_80_proportion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval 80%: (0.1869856177645281, 0.3273000965211861)\n"
     ]
    }
   ],
   "source": [
    "#calculating confidence interval for the confidence level of 90%\n",
    "interval_90_proportion = stats.norm.interval(alpha=cl_90, loc=p_hat_shop ,scale=shop_s_e)\n",
    "\n",
    "print(f\"Confidence interval 80%: {interval_90_proportion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 3 - More practice\n",
    "For the same example in challenge 1, calculate a confidence interval for the variance at 90% level.\n",
    "\n",
    "**Hint**: function `stats.chi2.interval` from `scipy` can help you get through this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining 1D np array heights\n",
    "heights = [167, 167, 168, 168, 168, 169, 171, 172, 173, 175, 175, 175, 177, 182, 195]\n",
    "\n",
    "pop_std = 4\n",
    "\n",
    "variance = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 1 - Calculating manually Chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating degree of freedom\n",
    "d_f = len(heights)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.12380952380952"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_chi = np.var(heights, ddof=1)\n",
    "sigma_chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating alpha\n",
    "alpha_heights = (1-variance)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.46666666666667"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heights_mean = np.mean(heights)\n",
    "heights_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# norm.interval(alpha_heights, loc=heights_mean, scale=s_d)\n",
    "#degrees of freedom at 90%\n",
    "upper_bound, lower_bound = chi2.interval(alpha=variance, df=d_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.570631383789342, 23.684791304840576)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upper_bound, lower_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.992400675216064"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating lower confidence_interval\n",
    "lower_confidence_interval = (len(heights)-1) * sigma_chi / lower_bound\n",
    "lower_confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115.32123613002646"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating upper confidence_interval\n",
    "upper_confidence_interval = (len(heights)-1) * sigma_chi / upper_bound\n",
    "upper_confidence_interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confidence interval is in between 31.992400675216064 to 115.32123613002646\n"
     ]
    }
   ],
   "source": [
    "print(f\"the confidence interval is in between {lower_confidence_interval} to {upper_confidence_interval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method 2 - Using stats.chi2.interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval 90%: [31.992400675216064, 115.32123613002646]\n"
     ]
    }
   ],
   "source": [
    "ddof = len(heights)-1\n",
    "score = stats.chi2.interval(0.9,ddof)\n",
    "\n",
    "# Parameters\n",
    "heights_quasi_var = np.var(heights) * (len(heights) / ddof)\n",
    "\n",
    "# Confidence interval\n",
    "conf_int = [ ddof * heights_quasi_var / score[1], ddof * heights_quasi_var / score[0]]\n",
    "print(f\"Confidence interval 90%: {conf_int}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge 4 - More practice\n",
    "The sulfuric acid content of 7 similar containers is 9.8, 10.2, 10.4, 9.8, 10.0, 10.2 and 9.6 liters. Calculate a 95% confidence interval for the average content of all containers assuming an approximately normal distribution.\n",
    "\n",
    "```\n",
    "acid = [9.8, 10.2, 10.4, 9.8, 10.0, 10.2, 9.6]\n",
    "```\n",
    "\n",
    "**Hint**: function `stats.t.interval` from `scipy` can help you get through this exercise. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.738414120176683, 10.261585879823317)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acid = [9.8, 10.2, 10.4, 9.8, 10.0, 10.2, 9.6]\n",
    "\n",
    "cl = 0.95\n",
    "\n",
    "df = (len(acid))-1\n",
    "\n",
    "t_student_mean = np.mean(acid)\n",
    "\n",
    "t_student_std  = np.std(acid) * np.sqrt(len(acid)/df) / np.sqrt(len(acid))\n",
    "\n",
    "stats.t.interval(cl, df=df,loc=np.mean(acid), scale=t_student_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "The error level or sampling error for the first challenge is given by the following expression:\n",
    "$$Error = z_{\\frac{\\alpha}{2}}\\frac{\\sigma}{\\sqrt n}$$\n",
    "Where z represents the value for N(0,1)\n",
    "\n",
    "\n",
    "Suppose that with the previous data of challenge 1, and with a confidence level of\n",
    "99% (that is, almost certainly) we want to estimate the average population size, so that the error level committed is not greater than half a centimeter.\n",
    "\n",
    "#### 1.- Determine what size the selected sample of men should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for an error lower 0.5cm, the sample size must be of : 425.0\n"
     ]
    }
   ],
   "source": [
    "# Variables\n",
    "heights = [167, 167, 168, 168, 168, 169, 171, 172, 173, 175, 175, 175, 177, 182, 195]\n",
    "pop_std = 4\n",
    "score = stats.norm.interval(0.99)[1]\n",
    "error = 0.5\n",
    "\n",
    "# Sample Size\n",
    "sample_size_root = score * pop_std / error\n",
    "# squaring the sqrt sample size\n",
    "sample_size = np.ceil(np.power(sample_size_root,2))\n",
    "\n",
    "print(f'for an error lower 0.5cm, the sample size must be of : {sample_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.- For the second challenge, we have the following error:\n",
    "$$ Error = z_{\\frac{\\alpha}{2}}\\sqrt{\\frac{p\\times q}{n}} $$\n",
    "#### Determine the sample size required to not exceed an error of 1% with a confidence of 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for an error lower than 1%, the sample size must be at least of : 3138 units\n"
     ]
    }
   ],
   "source": [
    "total_shop = 105\n",
    "loss_shop = 27\n",
    "error = 0.01\n",
    "cl = 0.8\n",
    "score = stats.norm.interval(0.80)[1]\n",
    "\n",
    "#Parameters\n",
    "p = loss_shop / total_shop\n",
    "q = 1 - p\n",
    "\n",
    "# Sample Size\n",
    "sample_size_root = score * np.sqrt(p * q) / error\n",
    "\n",
    "# squaring the sqrt sample size\n",
    "sample_size = int(np.ceil(np.power(sample_size_root,2)))\n",
    "sample_size\n",
    "\n",
    "print(f'for an error lower than 1%, the sample size must be at least of : {sample_size} units')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenge\n",
    "\n",
    "Let's consider the following problem:\n",
    "\n",
    "Build a confidence interval of 94% for the real difference between the durations of two brands of spotlights, if a sample of 40 spotlights taken randomly from the first mark gave an average duration of 418 hours, and a sample of 50 bulbs of another brand gave a duration average of 402 hours. The standard deviations of the two\n",
    "populations are 26 hours and 22 hours, respectively.\n",
    "\n",
    "Sometimes, we will be interested in the difference of two different groups of random variables. We can also build a confidence interval for that! We have some different cases regarding the variance but for this specific case (the variance are different and known), we have that:\n",
    "\n",
    "$$\\overline{X} - \\overline{Y}  \\sim N(\\mu_{X} - \\mu_{Y} , \\sqrt{\\frac{\\sigma_{X}^2}{n_X}+\\frac{\\sigma_{Y}^2}{n_Y}})$$\n",
    "\n",
    "Solve the problem with this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data \n",
    "cl = 0.94\n",
    "score = stats.norm.interval(0.94)[1]\n",
    "\n",
    "sample_40_duration = 418\n",
    "sample_50_duration = 402\n",
    "\n",
    "std_sample_40 = 26\n",
    "std_sample_50 = 22\n",
    "\n",
    "normal_mean = sample_40_duration-sample_50_duration\n",
    "std = np.sqrt(((np.power(std_sample_40,2))/40) + (np.power(std_sample_50,2)/50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.303419026585921, 25.69658097341408)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confidence interval\n",
    "stats.norm.interval(cl,loc=normal_mean,scale=std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
